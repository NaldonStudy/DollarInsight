"""
Prediction Training Pipeline Airflow DAG

ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” DAG
ë§¤ì£¼ í•œêµ­ì‹œê°„ ê¸°ì¤€ ë‚® 12ì‹œì— ì‹¤í–‰
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import sys
import os
import pytz
import datetime as dt

# Airflow utils ê²½ë¡œë¥¼ Python ê²½ë¡œì— ì¶”ê°€
airflow_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
utils_dir = os.path.join(airflow_dir, "utils")
if utils_dir not in sys.path:
    sys.path.insert(0, utils_dir)

# prediction_system ê²½ë¡œ ì¶”ê°€ (prediction_system ëª¨ë“ˆì„ importí•˜ê¸° ìœ„í•´)
prediction_system_dir = os.path.join(utils_dir, "prediction_system")
if prediction_system_dir not in sys.path:
    sys.path.insert(0, prediction_system_dir)

# pipelines ê²½ë¡œ ì¶”ê°€ (watchlists ëª¨ë“ˆìš©)
pipelines_dir = os.path.join(utils_dir, "pipelines")
if pipelines_dir not in sys.path:
    sys.path.insert(0, pipelines_dir)

# Lazy import: ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ importí•˜ì—¬ DAG íŒŒì‹± ì‹œ CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
# from prediction_system.pipelines.training_pipeline import (
#     run_pipeline as run_training_pipeline,
# )


# ê¸°ë³¸ ì¸ì ì„¤ì •
# í•œêµ­ ì‹œê°„(KST, UTC+9) ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
kst = pytz.timezone("Asia/Seoul")
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(hours=1),
    "start_date": datetime(2024, 1, 1, tzinfo=kst),  # í•œêµ­ ì‹œê°„ëŒ€ ì ìš©
}

# DAG ì •ì˜
# ë§¤ì£¼ ì›”ìš”ì¼ í•œêµ­ì‹œê°„ ê¸°ì¤€ ë‚® 12ì‹œ ì‹¤í–‰ (UTC ê¸°ì¤€: ë§¤ì£¼ ì›”ìš”ì¼ 03:00)
dag = DAG(
    "prediction_training",
    default_args=default_args,
    description="Prediction model training pipeline: Feature build â†’ Model training",
    schedule="0 3 * * 1",  # ë§¤ì£¼ ì›”ìš”ì¼ UTC 03:00 (í•œêµ­ì‹œê°„ ì›”ìš”ì¼ 12:00)
    catchup=False,
    max_active_runs=1,
    tags=["prediction", "training", "ml", "models"],
)


def run_training(**context):
    """ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    # Lazy import: ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ importí•˜ì—¬ DAG íŒŒì‹± ì‹œ CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
    from prediction_system.pipelines.training_pipeline import (
        run_pipeline as run_training_pipeline,
    )
    from datetime import datetime

    execution_date = context.get("execution_date") or context.get("data_interval_start")

    # execution_dateë¥¼ date ê°ì²´ë¡œ ë³€í™˜
    if isinstance(execution_date, datetime):
        target_date = execution_date.date()
    elif isinstance(execution_date, str):
        target_date = dt.date.fromisoformat(execution_date)
    else:
        target_date = dt.date.today() - dt.timedelta(days=1)

    # í•™ìŠµ ê¸°ê°„ ì„¤ì •: ìµœê·¼ 1ë…„ ë°ì´í„° ì‚¬ìš©
    train_end = target_date
    train_start = train_end - dt.timedelta(days=365)

    print(
        f"ğŸ”„ Prediction training pipeline ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    )
    print(f"ğŸ“… Execution date: {execution_date}")
    print(f"ğŸ“Š Training period: {train_start} ~ {train_end}")

    try:
        # í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        train_results = run_training_pipeline(
            train_start=train_start.isoformat(),
            train_end=train_end.isoformat(),
            feature_target=train_end.isoformat(),
            lookback_days=260,
            build_features=True,
        )

        if train_results:
            print(f"âœ… Prediction training pipeline ì™„ë£Œ")
            print(f"ğŸ“ˆ Trained models: {list(train_results.keys())}")
            for task_name, info in train_results.items():
                model_id = info.get("model_id", "N/A")
                print(f"   - {task_name}: {model_id}")
        else:
            print("âš ï¸ Training pipeline completed but no models were trained")

        return {
            "status": "success",
            "execution_date": str(execution_date),
            "train_start": train_start.isoformat(),
            "train_end": train_end.isoformat(),
            "trained_models": list(train_results.keys()) if train_results else [],
        }

    except Exception as e:
        print(f"âŒ Prediction training pipeline ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback

        traceback.print_exc()
        raise


# ì‘ì—… ì •ì˜
training_task = PythonOperator(
    task_id="run_training_pipeline",
    python_callable=run_training,
    dag=dag,
)
