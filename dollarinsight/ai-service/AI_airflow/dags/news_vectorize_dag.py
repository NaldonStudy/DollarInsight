"""
ë‰´ìŠ¤ ë²¡í„°í™” DAG
MongoDBì˜ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ KSSì™€ BGE-M3ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„°í™”í•˜ì—¬ ChromaDBì— ì €ì¥
ë‰´ìŠ¤ ì²˜ë¦¬ í›„ ì‹¤í–‰ (ë§¤ì¼ ì˜¤ì „ 3ì‹œ 30ë¶„)
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import sys
import os
import pytz

# Airflow utils ê²½ë¡œë¥¼ Python ê²½ë¡œì— ì¶”ê°€
airflow_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
utils_dir = os.path.join(airflow_dir, "utils")
if utils_dir not in sys.path:
    sys.path.insert(0, utils_dir)

# ëª¨ë“ˆ ë ˆë²¨ import ì œê±° (íŒŒì‹± ì‹œ CPU ê³¼ë¶€í•˜ ë°©ì§€)
# ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬(FlagEmbedding, kss, chromadb) ë¡œë”©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´
# í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ importí•˜ë„ë¡ ë³€ê²½
# from vectorize_news import vectorize_news

# ê¸°ë³¸ ì¸ì ì„¤ì •
# í•œêµ­ ì‹œê°„(KST, UTC+9) ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
kst = pytz.timezone("Asia/Seoul")
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=10),
    "start_date": datetime(2024, 1, 1, tzinfo=kst),  # í•œêµ­ ì‹œê°„ëŒ€ ì ìš©
}

# DAG ì •ì˜
dag = DAG(
    "news_vectorize",
    default_args=default_args,
    description="ë‰´ìŠ¤ ë²¡í„°í™” - MongoDB ë‰´ìŠ¤ë¥¼ ChromaDBì— ë²¡í„°í™”í•˜ì—¬ ì €ì¥",
    schedule="30 3 * * *",  # ë§¤ì¼ ì˜¤ì „ 3ì‹œ 30ë¶„ ì‹¤í–‰ (ë‰´ìŠ¤ ì²˜ë¦¬ í›„, í•œêµ­ ì‹œê°„ ê¸°ì¤€)
    catchup=False,
    max_active_runs=1,
    max_active_tasks=1,
    tags=["news", "vectorize", "chromadb"],
)


def vectorize_news_task(**context):
    """ë‰´ìŠ¤ ë²¡í„°í™” ì‹¤í–‰"""
    from datetime import datetime
    
    # ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ importë¥¼ í•¨ìˆ˜ ë‚´ë¶€ë¡œ ì´ë™ (íŒŒì‹± ì‹œ CPU ê³¼ë¶€í•˜ ë°©ì§€)
    from vectorize_news import vectorize_news
    
    print(f"ğŸ”„ ë‰´ìŠ¤ ë²¡í„°í™” ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # MongoDBì˜ ëª¨ë“  ë‰´ìŠ¤ë¥¼ ë²¡í„°í™”í•˜ì—¬ ChromaDBì— ì €ì¥
        # limit=None: ëª¨ë“  ê¸°ì‚¬ ì²˜ë¦¬
        # skip=0: ì²˜ìŒë¶€í„° ì²˜ë¦¬
        stats = vectorize_news(
            limit=None,  # ëª¨ë“  ê¸°ì‚¬ ì²˜ë¦¬
            skip=0,  # ì²˜ìŒë¶€í„°
            collection_name=None  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´
        )
        
        # Airflow XComì— ê²°ê³¼ ì €ì¥
        context["ti"].xcom_push(key="total_articles", value=stats.get("total_articles", 0))
        context["ti"].xcom_push(key="total_chunks", value=stats.get("total_chunks", 0))
        context["ti"].xcom_push(key="saved_chunks", value=stats.get("saved_chunks", 0))
        context["ti"].xcom_push(key="errors", value=stats.get("errors", 0))
        
        return {
            "status": "success",
            "total_articles": stats.get("total_articles", 0),
            "total_chunks": stats.get("total_chunks", 0),
            "saved_chunks": stats.get("saved_chunks", 0),
            "errors": stats.get("errors", 0),
        }
        
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ë²¡í„°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


# ë‰´ìŠ¤ ë²¡í„°í™” ì‘ì—… ì •ì˜
vectorize_task = PythonOperator(
    task_id="vectorize_news",
    python_callable=vectorize_news_task,
    dag=dag,
)

# ì‘ì—… ì‹¤í–‰
vectorize_task

