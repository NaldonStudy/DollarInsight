"""
AutoGen ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í† ë¡ ì‹œìŠ¤í…œ - íŒŒì´í”„ë¼ì¸
ë‹¤ë¥¸ ëª¨ë“ˆë“¤ì„ í†µí•©í•˜ì—¬ ì „ì²´ í† ë¡  ì‹œìŠ¤í…œì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ íŒŒì´í”„ë¼ì¸
"""

# ===== ì‚¬ìš©ì ì„¤ì • =====
INITIAL_MESSAGE = "ì‚¼ì„±ì „ì ì£¼ì‹ì— ëŒ€í•´ íˆ¬ì ì˜ê²¬ì„ ë‚˜ëˆ ì£¼ì„¸ìš”."
MAX_ROUNDS = 15
AUTO_MAX_ROUNDS = 7  # ì‚¬ìš©ì ì…ë ¥ ì—†ì´ ìë™ ì§„í–‰ ì‹œ ìµœëŒ€ ë¼ìš´ë“œ (6~8 ì‚¬ì´)
USE_RERANK = False
USE_POSTGRES = False
INPUT_TIMEOUT = 3
PAUSE_MODE = False
# í™œì„± ì—ì´ì „íŠ¸ (ë°œì–¸ ìˆœì„œëŠ” ëœë¤, ì§ì „ ë°œì–¸ìëŠ” ì œì™¸)
ACTIVE_AGENTS = ["ë¯¼ì§€", "í¬ì—´", "í…Œì˜¤", "ì§€ìœ¨", "ë•ìˆ˜"]
MAX_CONTEXT_MESSAGES = 3

# ===== Import =====
import os
import sys
from pathlib import Path
import logging
import warnings
import random
import queue
import traceback
import signal
import time
import threading

# í˜„ì¬ íŒŒì¼ì´ ìˆëŠ” FastAPI í´ë”ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
CURRENT_DIR = Path(__file__).resolve().parent
if str(CURRENT_DIR) not in sys.path:
    sys.path.insert(0, str(CURRENT_DIR))

warnings.filterwarnings("ignore", message=".*flaml.automl.*")
warnings.filterwarnings("ignore", message=".*XLMRobertaTokenizerFast.*")
warnings.filterwarnings("ignore", message=".*fast tokenizer.*")
logging.getLogger("transformers").setLevel(logging.ERROR)
logging.getLogger().setLevel(logging.ERROR)

from dotenv import load_dotenv

load_dotenv()

from autogen import ConversableAgent, UserProxyAgent

from database import (
    OPENAI_API_KEY,
    GMS_BASE_URL,
    load_agent_collections,
    search_postgres,
)
from search import keyword_search_bm25, semantic_search_vector
from prompts import create_all_agents

# ===== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ =====


def input_with_timeout(prompt, timeout=INPUT_TIMEOUT):
    """íƒ€ì„ì•„ì›ƒì´ ìˆëŠ” ì…ë ¥ í•¨ìˆ˜ (í•œê¸€ ì§€ì›)"""
    print(prompt, end="", flush=True)

    if sys.platform != "win32":

        def timeout_handler(signum, frame):
            raise TimeoutError("ì…ë ¥ íƒ€ì„ì•„ì›ƒ")

        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(timeout)
        try:
            line = input()
            signal.alarm(0)
            return line
        except TimeoutError:
            signal.alarm(0)
            print(f"\n[íƒ€ì„ì•„ì›ƒ {timeout}ì´ˆ] ìë™ ì§„í–‰")
            return ""
    else:
        result_queue = queue.Queue()
        done = threading.Event()

        def read_input():
            try:
                line = (
                    input()
                    if sys.stdin.isatty()
                    else sys.stdin.readline().rstrip("\n\r")
                )
                result_queue.put(line)
            except (EOFError, KeyboardInterrupt):
                result_queue.put("")
            finally:
                done.set()

        input_thread = threading.Thread(target=read_input, daemon=True)
        input_thread.start()

        start_time = time.time()
        while time.time() - start_time < timeout:
            if done.is_set():
                try:
                    return result_queue.get_nowait()
                except queue.Empty:
                    return ""
            time.sleep(0.1)

        print(f"\n[íƒ€ì„ì•„ì›ƒ {timeout}ì´ˆ] ìë™ ì§„í–‰")
        return ""


def get_llm_config(model_name, temperature):
    """LLM ì„¤ì • ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
    # temperatureë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ëª©ë¡
    # - ì¶”ë¡  ëª¨ë¸(o1, o3 ì‹œë¦¬ì¦ˆ)
    # - nano ëª¨ë¸ë“¤(gpt-5-nano ë“± ê²½ëŸ‰ ëª¨ë¸)
    NO_TEMPERATURE_MODELS = [
        "o1",
        "o1-mini",
        "o1-preview",
        "o3",
        "o3-mini",
        "o3-pro",
        "nano",
    ]

    # ëª¨ë“  ëª¨ë¸ì„ GPTë¡œ ì‚¬ìš© (Gemini ì»¤ìŠ¤í…€ í´ë¼ì´ì–¸íŠ¸ëŠ” ë‚˜ì¤‘ì— ì¶”ê°€ ì˜ˆì •)
    # í˜•ì‹: POST /v1/chat/completions (Authorization: Bearer {GMS_KEY})
    config_dict = {
        "config_list": [
            {"model": model_name, "api_key": OPENAI_API_KEY, "base_url": GMS_BASE_URL}
        ],
    }

    # temperatureë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë¸ë§Œ temperature ì¶”ê°€
    if not any(no_temp_model in model_name for no_temp_model in NO_TEMPERATURE_MODELS):
        config_dict["temperature"] = temperature

    return config_dict


# ===== í˜ë¥´ì†Œë‚˜ ìƒì„± =====
_all_agents = create_all_agents(
    ConversableAgent_class=ConversableAgent,
    UserProxyAgent_class=UserProxyAgent,
    get_llm_config_func=get_llm_config,
    load_agent_collections_func=load_agent_collections,
    keyword_search_func=keyword_search_bm25,
    semantic_search_func=semantic_search_vector,
    search_postgres_func=search_postgres,
    use_rerank=USE_RERANK,
)

ë¯¼ì§€ = _all_agents["ë¯¼ì§€"]
í¬ì—´ = _all_agents["í¬ì—´"]
í…Œì˜¤ = _all_agents["í…Œì˜¤"]
ì§€ìœ¨ = _all_agents["ì§€ìœ¨"]
ë•ìˆ˜ = _all_agents["ë•ìˆ˜"]
user = _all_agents["user"]


# ===== ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ =====


def run():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ’¥ AI íˆ¬ì í† ë¡  ë°°í‹€ ì‹œì‘ ğŸ’¥")
    print("=" * 50)
    print("ğŸ² 5ëª…ì˜ ì—ì´ì „íŠ¸ê°€ ê²©ë ¬í•˜ê²Œ í† ë¡ í•©ë‹ˆë‹¤!")
    print("ğŸ”¥ í¬ì—´(ê³µê²©ì ) vs ë•ìˆ˜(ë³´ìˆ˜ì ) vs ì§€ìœ¨(ëƒ‰ì² )")
    print("ğŸš€ í…Œì˜¤(ë¯¸ë˜íŒŒ) vs ë¯¼ì§€(íŠ¸ë Œë“œíŒŒ)")
    print(f"â±ï¸  ìë™ ì§„í–‰ {AUTO_MAX_ROUNDS}ë¼ìš´ë“œ (Enterë¡œ ê³„ì†)")
    print("=" * 50)

    messages = [{"content": INITIAL_MESSAGE, "role": "user", "name": "user"}]

    all_agents = {
        "ë¯¼ì§€": ë¯¼ì§€,
        "í¬ì—´": í¬ì—´,
        "í…Œì˜¤": í…Œì˜¤,
        "ì§€ìœ¨": ì§€ìœ¨,
        "ë•ìˆ˜": ë•ìˆ˜,
    }
    ai_agents = [all_agents[name] for name in ACTIVE_AGENTS if name in all_agents]

    print(
        f"í™œì„± ì—ì´ì „íŠ¸: {', '.join([a.name for a in ai_agents])} / ì´ {len(ai_agents)}ëª…"
    )

    last_speaker = None
    turns = 0
    auto_turns = 0  # ì‚¬ìš©ì ì…ë ¥ ì—†ì´ ì§„í–‰ëœ í„´ ìˆ˜
    limit_msgs = MAX_ROUNDS * 10
    spoken_agents = set()  # ë°œì–¸í•œ ì—ì´ì „íŠ¸ ì¶”ì 

    while turns < MAX_ROUNDS * 5:
        print("\n" + "=" * 60)
        print(f"í„´ {turns + 1} ì‹œì‘")
        print("=" * 60)

        # ëª¨ë“  ì—ì´ì „íŠ¸ì—ê²Œ ìµœì†Œ 1ë²ˆ ë°œì–¸ê¶Œ ë³´ì¥
        if len(spoken_agents) < len(ai_agents):
            # ì•„ì§ ë°œì–¸ ì•ˆ í•œ ì—ì´ì „íŠ¸ ì¤‘ì—ì„œ ì„ íƒ
            not_spoken = [a for a in ai_agents if a not in spoken_agents]
            speaker = random.choice(not_spoken)
        else:
            # ëª¨ë‘ ë°œì–¸í–ˆìœ¼ë©´ ëœë¤ ì„ íƒ (ì§ì „ ë°œì–¸ì ì œì™¸)
            available = [a for a in ai_agents if a != last_speaker]
            speaker = (
                random.choice(available) if available else random.choice(ai_agents)
            )

        spoken_agents.add(speaker)
        last_speaker = speaker

        # ì—ì´ì „íŠ¸ë³„ ì´ëª¨ì§€
        emojis = {"í¬ì—´": "ğŸ”¥", "ë•ìˆ˜": "ğŸ§˜", "ì§€ìœ¨": "ğŸ“Š", "í…Œì˜¤": "ğŸš€", "ë¯¼ì§€": "ğŸ“±"}
        emoji = emojis.get(speaker.name, "ğŸ’¬")

        print(f"\n{emoji} [{speaker.name}] ë°œì–¸ ì°¨ë¡€")

        try:
            print("-" * 60)

            if user not in speaker.chat_messages:
                speaker.chat_messages[user] = []

            limited_messages = (
                messages[-MAX_CONTEXT_MESSAGES:]
                if len(messages) > MAX_CONTEXT_MESSAGES
                else messages
            )
            if len(messages) > MAX_CONTEXT_MESSAGES:
                print(
                    f"[ì»¨í…ìŠ¤íŠ¸ ì œí•œ] {len(messages)}ê°œ ë©”ì‹œì§€ â†’ {len(limited_messages)}ê°œë¡œ ì œí•œ (ìµœê·¼ {MAX_CONTEXT_MESSAGES}ê°œ)"
                )

            speaker.chat_messages[user] = limited_messages
            result = speaker.generate_reply(messages=limited_messages, sender=user)
            reply = result[1] if isinstance(result, tuple) else result

            if reply:
                ai_resp = str(reply)
                emoji = emojis.get(speaker.name, "ğŸ’¬")
                print("\n" + "â–¶" * 30)
                print(f"{emoji} {speaker.name}ì˜ ì˜ê²¬:")
                print("â–¶" * 30)
                print(ai_resp)
                print("â–¶" * 30)

                # ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ (PG, BM25, Vector êµ¬ë¶„)
                if hasattr(speaker, "_last_search_results"):
                    # ê°€ì¥ ìµœê·¼ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                    if speaker._last_search_results:
                        latest_key = list(speaker._last_search_results.keys())[-1]
                        search_data = speaker._last_search_results[latest_key]

                        print("\n[ê²€ìƒ‰ ê·¼ê±°]")

                        # PostgreSQL ê²°ê³¼
                        if search_data.get("postgres"):
                            print("\n  ğŸ“Š PostgreSQL (ì¬ë¬´ ë°ì´í„°):")
                            for idx, result in enumerate(
                                search_data["postgres"][:2], 1
                            ):
                                preview = (
                                    result[:150] + "..."
                                    if len(result) > 150
                                    else result
                                )
                                print(f"    {idx}. {preview}")

                        # BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼
                        if search_data.get("bm25"):
                            print("\n  ğŸ” BM25 í‚¤ì›Œë“œ ê²€ìƒ‰:")
                            for idx, result in enumerate(search_data["bm25"][:2], 1):
                                preview = (
                                    result[:150] + "..."
                                    if len(result) > 150
                                    else result
                                )
                                print(f"    {idx}. {preview}")

                        # Vector ì˜ë¯¸ ê²€ìƒ‰ ê²°ê³¼
                        if search_data.get("vector"):
                            print("\n  ğŸ§  Vector ì˜ë¯¸ ê²€ìƒ‰:")
                            for idx, result in enumerate(search_data["vector"][:2], 1):
                                preview = (
                                    result[:150] + "..."
                                    if len(result) > 150
                                    else result
                                )
                                print(f"    {idx}. {preview}")

                        if not any(
                            [
                                search_data.get("postgres"),
                                search_data.get("bm25"),
                                search_data.get("vector"),
                            ]
                        ):
                            print("  (ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)")

                messages.append(
                    {"content": ai_resp, "role": "assistant", "name": speaker.name}
                )
        except Exception as e:
            print(f"AI ë°œì–¸ ì—ëŸ¬: {type(e).__name__}: {e}")
            traceback.print_exc()
            break

        print("\n" + "=" * 60)
        if PAUSE_MODE:
            print("ì¼ì‹œì¤‘ë‹¨ ëª¨ë“œ - ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°")
        else:
            print("ì‚¬ìš©ì ì…ë ¥ (Enter: ê³„ì†, ë©”ì‹œì§€: í† ë¡  ì°¸ì—¬)")
        print("=" * 60)

        user_input = (
            input("> ") if PAUSE_MODE else input_with_timeout("> ", INPUT_TIMEOUT)
        )

        if user_input.strip():
            # ì‚¬ìš©ì ì…ë ¥ì´ ìˆìœ¼ë©´ ìë™ í„´ ì¹´ìš´í„° ë¦¬ì…‹
            messages.append({"content": user_input, "role": "user", "name": "user"})
            print("\nì‚¬ìš©ì:")
            print("-" * 40)
            print(user_input)
            print("-" * 40)
            auto_turns = 0  # ì¹´ìš´í„° ë¦¬ì…‹
        else:
            # ì‚¬ìš©ì ì…ë ¥ì´ ì—†ìœ¼ë©´ ìë™ í„´ ì¦ê°€
            auto_turns += 1
            if auto_turns >= AUTO_MAX_ROUNDS:
                print("\n" + "ğŸ" * 30)
                print(f"ğŸ’¥ {AUTO_MAX_ROUNDS}ë¼ìš´ë“œ ì™„ë£Œ! í† ë¡  ì¢…ë£Œ!")
                print("ğŸ" * 30)
                break

        turns += 1
        if len(messages) >= limit_msgs:
            print("\n" + "=" * 60)
            print("ìµœëŒ€ í„´ ë„ë‹¬ - í† ë¡  ì¢…ë£Œ")
            print("=" * 60)
            break


if __name__ == "__main__":
    run()
